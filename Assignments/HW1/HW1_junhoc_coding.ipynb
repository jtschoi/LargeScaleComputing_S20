{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1, MACS 30123, Coding Appendix\n",
    "#### Professor Jon Clindaniel\n",
    "#### Submitted by Junho Choi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A. Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A-(1) q1_actual.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sts\n",
    "import time\n",
    "\n",
    "def q1_mpi_helper(mu, n_runs, n_steps, eps_sub, rho):\n",
    "    '''\n",
    "    Helper function to be run for each process\n",
    "\n",
    "    Input:\n",
    "    - mu: parameter for the AR(1) process\n",
    "    - n_runs: number of lives to simulate\n",
    "    - n_steps: number of periods to simulate\n",
    "    - eps_sub: epsilon_t matrix of size (epr, n_steps)\n",
    "    - rho: parameter for the AR(1) process\n",
    "\n",
    "    Output:\n",
    "    - result_mat: sub-simulation completed for this process;\n",
    "        should be the same size as eps_sub\n",
    "\n",
    "    '''\n",
    "    # place to record the computations\n",
    "    result_mat = np.zeros_like(eps_sub)\n",
    "\n",
    "    # computation process; requires for loop to do a scan-like operation\n",
    "    for i in range(int(n_steps)):\n",
    "        if i == 0:\n",
    "            input_col = eps_sub[:, i]\n",
    "        else:\n",
    "            input_col = result_mat[:, i-1] * rho + eps_sub[:, i]\n",
    "        result_mat[:, i] = input_col\n",
    "\n",
    "    # add mu to finish things\n",
    "    result_mat = result_mat + np.float32(mu)   \n",
    "\n",
    "    return result_mat\n",
    "\n",
    "def q1_mpi(n_runs=1000, n_steps=4160, mu=3.0, sigma=1.0,\n",
    "           rho=0.5, rand_seed=25):\n",
    "    '''\n",
    "    mpi4py implementation of the AR(1) process simulation.\n",
    "\n",
    "    Input:\n",
    "    - n_runs: number of lives to simulate\n",
    "    - n_steps: number of periods to simulate\n",
    "    - mu: parameter for the AR(1) process; also starting health level\n",
    "    - sigma: scale for the epsilons ~ N(0, sigma)\n",
    "    - rho: parameter for the AR(1) process\n",
    "    - rand_seed: randomization seed for replicability\n",
    "\n",
    "    Output:\n",
    "    - t1 (printed): seconds elapsed for total simulation\n",
    "\n",
    "    '''\n",
    "    # Get rank of process and overall size of communicator\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "\n",
    "    # start time\n",
    "    t0 = time.time()\n",
    "\n",
    "    # initializing the error matrix\n",
    "    np.random.seed(rand_seed)\n",
    "    eps_mat = sts.norm.rvs(loc=0, scale=sigma, size=(n_runs, n_steps))\n",
    "\n",
    "    # eps per rank\n",
    "    epr = int(n_runs/size)\n",
    "\n",
    "    # cases of epsilons to be used in this rank  \n",
    "    eps_sub = eps_mat[int(epr*rank):int(epr*(rank+1)), :]\n",
    "                                          \n",
    "    # calculation for the sub-case, using the helper function\n",
    "    # sub_result will contain the average lengths till nonpositive health\n",
    "    # for each of the rhos in rho_sub\n",
    "    sub_result = q1_mpi_helper(mu, n_runs, n_steps, eps_sub, rho)\n",
    "\n",
    "    # preparing the results into a vector\n",
    "    sub_result_vec = sub_result.flatten()\n",
    "\n",
    "    # getting a container for gathering the sub-results\n",
    "    results = None\n",
    "    if rank == 0:\n",
    "        # should be epr*n_steps\n",
    "        subcase_length = sub_result_vec.shape[0]\n",
    "        results = np.empty(int(subcase_length*size), dtype='float')\n",
    "\n",
    "    # gathering the results\n",
    "    comm.Gatherv(sendbuf=sub_result_vec, recvbuf=results, root=0)\n",
    "\n",
    "    # printing the results in rank 0\n",
    "    if rank == 0:\n",
    "        # reformatting as dataframe-style\n",
    "        df = results.reshape((int(epr*size), n_steps))\n",
    "\n",
    "        # elapsed time\n",
    "        t1 = time.time() - t0\n",
    "        print(\"Simulation required %10.6f seconds\" % t1)\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    q1_mpi()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A-(2) q1.sbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows an example for using 17 cores; numbers should be changed corresponding to the number of cores to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name=q1\n",
    "#SBATCH --output=q1_core17.out\n",
    "#SBATCH --error=q1_output.err\n",
    "#SBATCH --ntasks=17\n",
    "#SBATCH --partition=broadwl\n",
    "#SBATCH --constraint=fdr\n",
    "\n",
    "module load mpi4py/3.0.1a0_py3\n",
    "\n",
    "mpirun -n 17 python ./q1_actual.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B. Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-(1) q2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "import pyopencl.array as cl_array\n",
    "import pyopencl.clrandom as clrand\n",
    "import pyopencl.tools as cltools\n",
    "import scipy.stats as sts\n",
    "import time\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "\n",
    "from pyopencl.scan import GenericScanKernel\n",
    "\n",
    "def q2(n_runs=1000, n_steps=4160, mu=3, sigma=1, rho=0.5,\n",
    "       rand_seed=25):\n",
    "    '''\n",
    "    AR(1) process simulation of (n_runs) lives for (n_steps) periods\n",
    "    \n",
    "    Input:\n",
    "    - n_runs: number of lives to simulate\n",
    "    - n_steps: number of periods to simulate\n",
    "    - mu: parameter value; also used as starting point\n",
    "    - sigma: standard dev. of the error term (~N(0, sigma))\n",
    "    - rho: parameter of the AR(1) process\n",
    "    - rand_seed: random seed for replication reasons (for the errors)\n",
    "\n",
    "    Output:\n",
    "    - elapsed (printed): time taken for overall computation\n",
    "\n",
    "    '''\n",
    "    # Set up OpenCL context and command queue\n",
    "    ctx = cl.create_some_context()\n",
    "    queue = cl.CommandQueue(ctx)\n",
    "\n",
    "    # timing starts\n",
    "    t0 = time.time()\n",
    "\n",
    "    # generating a vector of epsilons (errors); length n_runs*n_steps\n",
    "    NT = int(n_runs*n_steps)\n",
    "    rand_gen = clrand.PhiloxGenerator(ctx, seed=rand_seed)\n",
    "    eps = rand_gen.normal(queue, NT, np.float32,\n",
    "                          mu=0, sigma=sigma)\n",
    "    \n",
    "    # establishing boundaries for each simulated walk\n",
    "    # necessary for performing scans only within lives and not between\n",
    "    seg_boundaries = [1] + [0]*(n_steps-1)\n",
    "    seg_boundaries = np.array(seg_boundaries, dtype=np.uint8)\n",
    "    seg_boundary_flags = np.tile(seg_boundaries, int(n_runs))\n",
    "    seg_boundary_flags = cl_array.to_device(queue, seg_boundary_flags)\n",
    "\n",
    "    # Defining segmented kernel operation\n",
    "    prefix_sum = GenericScanKernel(ctx, np.float32,\n",
    "                 arguments=\"__global float *ary, __global char *segflags, \"\n",
    "                           \"__global float rho, __global float *out\",\n",
    "                 input_expr=\"ary[i]\",\n",
    "                 scan_expr=\"across_seg_boundary ? b : (rho*a+b)\", neutral=\"0\",\n",
    "                 is_segment_start_expr=\"segflags[i]\",\n",
    "                 output_statement=\"out[i] = item\",\n",
    "                 options=[])\n",
    "\n",
    "    # Allocate space for result of kernel on device\n",
    "    dev_result = cl_array.empty_like(eps)\n",
    "\n",
    "    # Enqueue and Run Scan Kernel\n",
    "    prefix_sum(eps, seg_boundary_flags, rho, dev_result)\n",
    "\n",
    "    # need to add mu to everything, after retrieval\n",
    "    simulation_done = dev_result.get()\n",
    "    simulation_done = simulation_done + mu\n",
    "\n",
    "    # Results transformed into a matrix form\n",
    "    simulation_done = simulation_done.reshape((n_runs, n_steps))\n",
    "\n",
    "    # elapsed time\n",
    "    final_time = time.time()\n",
    "    elapsed = final_time - t0\n",
    "    print(\"Simulation required %10.6f seconds\" % elapsed)\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    q2()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-(2) q2.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=gpu      # job name\n",
    "#SBATCH --output=q2_try.out # output log file\n",
    "#SBATCH --error=q2_try.err  # error file\n",
    "#SBATCH --time=00:20:00  # 5 minutes of wall time\n",
    "#SBATCH --nodes=1        # 1 GPU node\n",
    "#SBATCH --partition=gpu2 # GPU2 partition\n",
    "#SBATCH --ntasks=1       # 1 CPU core to drive GPU\n",
    "#SBATCH --gres=gpu:1     # Request 1 GPU\n",
    "\n",
    "module load cuda\n",
    "module load mpi4py/3.0.1a0_py3\n",
    "\n",
    "python ./q2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C. Question 3-(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C-(1) q3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sts\n",
    "import time\n",
    "\n",
    "def q3_mpi_helper(mu, n_runs, n_steps, eps_mat, rho_sub):\n",
    "    '''\n",
    "    Helper function to be run for each process,\n",
    "    calculating the average length till reaching nonpositive\n",
    "    health event\n",
    "\n",
    "    Input:\n",
    "    - mu: parameter for the AR(1) process\n",
    "    - n_runs: number of lives to simulate\n",
    "    - n_steps: number of periods to simulate\n",
    "    - eps_mat: epsilon_t matrix of size (n_runs, n_steps)\n",
    "    - rho_sub: subcase of rhos to be tested\n",
    "\n",
    "    Output:\n",
    "    - mean_per_rho: numpy array to contain the average lengths till\n",
    "        reaching nonpositive health event (for given values of rho);\n",
    "        same length as rho_sub\n",
    "\n",
    "    '''\n",
    "\n",
    "    # stacking the eps\n",
    "    rho_n = int(rho_sub.shape[0])\n",
    "    eps_stack = np.tile(eps_mat, (rho_n, 1))\n",
    "\n",
    "    # rho stacked, for computation\n",
    "    rho_stack = np.tile(rho_sub.reshape((rho_n, 1)), int(n_runs)).flatten()\n",
    "\n",
    "    # place to record the computations\n",
    "    result_mat = np.zeros_like(eps_stack)\n",
    "\n",
    "    # computation process; requires for loop to do a scan-like operation\n",
    "    for i in range(int(n_steps)):\n",
    "        if i == 0:\n",
    "            input_col = eps_stack[:, i]\n",
    "        else:\n",
    "            input_col = result_mat[:, i-1] * rho_stack + eps_stack[:, i]\n",
    "        result_mat[:, i] = input_col\n",
    "\n",
    "    # add mu to finish things\n",
    "    result_mat = result_mat + np.float32(mu)   \n",
    "\n",
    "    # finding the first occurrence of nonpositive health case\n",
    "    res = np.argmax(result_mat <= 0, axis=1)\n",
    "    res = res.reshape((rho_n, int(n_runs)))\n",
    "    mean_per_rho = res.mean(axis=1)\n",
    "\n",
    "    return mean_per_rho\n",
    "\n",
    "def q3_mpi(n_runs=1000, n_steps=4160, mu=3.0, sigma=1.0,\n",
    "           rho_ub=0.95, rho_lb=-0.95, rho_n=200, rand_seed=25):\n",
    "    '''\n",
    "    mpi4py implementation of the \"embarrassingly parallel\" simulation\n",
    "    of calculating average lengths till reaching nonpositive\n",
    "    health event.\n",
    "\n",
    "    Input:\n",
    "    - n_runs: number of lives to simulate\n",
    "    - n_steps: number of periods to simulate\n",
    "    - mu: parameter for the AR(1) process; also starting health level\n",
    "    - sigma: scale for the epsilons ~ N(0, sigma)\n",
    "    - rho_ub: upper bound for rho (parameter for the AR(1) process)\n",
    "    - rho_lb: lower bound for rho\n",
    "    - rho_n: cases of rhos to test in this grid search\n",
    "    - rand_seed: randomization seed for replicability\n",
    "\n",
    "    Output:\n",
    "    - t1 (printed): elapsed computation time\n",
    "    - q3_mpi.csv: collecting the dataset containing the rho values and\n",
    "        corresponding average lengths\n",
    "    - best_rho, best_length (printed): optimal rho value and the\n",
    "        corresponding average length\n",
    "\n",
    "    '''\n",
    "    # Get rank of process and overall size of communicator\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "\n",
    "    # start time\n",
    "    t0 = time.time()\n",
    "\n",
    "    # initializing the error matrix\n",
    "    np.random.seed(rand_seed)\n",
    "    eps_mat = sts.norm.rvs(loc=0, scale=sigma, size=(n_runs, n_steps))\n",
    "\n",
    "    # rho cases setup\n",
    "    rpc = int(rho_n/size)\n",
    "\n",
    "    # total cases of rho\n",
    "    rho_cases = np.linspace(rho_lb, rho_ub, rho_n, dtype=np.float32)\n",
    "\n",
    "    # cases of rho to be tested in this rank  \n",
    "    rho_sub = rho_cases[int(rank*rpc):int(rpc*(rank+1))]\n",
    "                                          \n",
    "    # calculation for the sub-case, using the helper function\n",
    "    # sub_result will contain the average lengths till nonpositive health\n",
    "    # for each of the rhos in rho_sub\n",
    "    sub_result = q3_mpi_helper(mu, n_runs, n_steps, eps_mat, rho_sub)\n",
    "\n",
    "    # preparing the results into a vector (rho and avg length alternating)\n",
    "    sub_result_vec = np.vstack((rho_sub, sub_result)).T.flatten()\n",
    "\n",
    "    # getting a container for gathering the sub-results\n",
    "    results = None\n",
    "    if rank == 0:\n",
    "        results = np.empty(int(2*rpc*size), dtype='float')\n",
    "\n",
    "    # gathering the results\n",
    "    comm.Gatherv(sendbuf=sub_result_vec, recvbuf=results, root=0)\n",
    "\n",
    "    # printing the results in rank 0\n",
    "    if rank == 0:\n",
    "        # reformatting as dataframe-style\n",
    "        df = results.reshape((int(rpc*size), 2))\n",
    "\n",
    "        # recording and printing the best cases\n",
    "        loca = np.argmax(df[:, 1])\n",
    "        best_rho = df[loca, 0]\n",
    "        best_length = df[loca, 1]\n",
    "\n",
    "        print(\"Best avg. length of periods is %10.6f\" % best_length)\n",
    "        print(\"This is achieved by rho of %6.5f\" % best_rho)\n",
    "\n",
    "        # exporting the collected dataset\n",
    "        df = pd.DataFrame(df, columns=['rho', 'avg_length'])\n",
    "        df.to_csv(\"q3_mpi.csv\", index=False)\n",
    "\n",
    "        # elapsed time\n",
    "        t1 = time.time() - t0\n",
    "        print(\"Simulation required %10.6f seconds\" % t1)\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    q3_mpi()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C-(2) q3_a.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=q3_try   # job name\n",
    "#SBATCH --output=q3_mpi.out # output log\n",
    "#SBATCH --error=q3_mpi.err  # error file\n",
    "#SBATCH --ntasks=20         # cores\n",
    "#SBATCH --partition=broadwl # Broadwell partition\n",
    "#SBATCH --constraint=fdr    # FDR constraint\n",
    "\n",
    "module load mpi4py/3.0.1a0_py3\n",
    "\n",
    "mpirun -n 20 python ./q3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D. Question 3-(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D-(1) q3_gpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "import pyopencl.array as cl_array\n",
    "import pyopencl.clrandom as clrand\n",
    "import pyopencl.tools as cltools\n",
    "import scipy.stats as sts\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from pyopencl.scan import GenericScanKernel\n",
    "import scipy.optimize as opt\n",
    "\n",
    "def crit_fn(par, *args):\n",
    "    '''\n",
    "    Criterion function to be used in PyOpenCL implementation\n",
    "    of finding optimal rho (and average length of periods)\n",
    "    using scipy.optimize.minimize_scalar and also the\n",
    "    \"embarrassing\" approach.\n",
    "\n",
    "    Inputs:\n",
    "    - par: the rho value to be tested (and optimized later)\n",
    "    - *args: broken down into...\n",
    "        - mu: mu value used in the AR(1) process\n",
    "        - shaping: length-2 tuple; =(n_runs, n_steps)\n",
    "        - eps: PyOpenCL array (length n_runs*n_steps) of AR(1) errors\n",
    "        - boundaries: PyOpenCL array of segmented boundaries, to be\n",
    "            used in the scan kernel\n",
    "        - prefix_sum: scan kernel implementation for calculating the\n",
    "            weighted (by rho and its powers) sum of errors (in eps)\n",
    "    \n",
    "    Outputs:\n",
    "    - rtn_val: negative of the average length of periods until\n",
    "        reaching nonpositive health outcomes; negative one is multiplied\n",
    "        as we are using a minimization function (to find the maximum\n",
    "        average length)\n",
    "\n",
    "    '''\n",
    "    ## unravelling the arguments\n",
    "    mu, shaping, eps, boundaries, prefix_sum = args\n",
    "    rho = par\n",
    "\n",
    "    ## generating an array of results, then calculating the AR(1) process\n",
    "    results = cl_array.empty_like(eps)\n",
    "    prefix_sum(eps, boundaries, rho, results)\n",
    "    results = results + mu\n",
    "\n",
    "    ## reshaping; row = number of lives, column = number of periods\n",
    "    res = results.get().reshape(shaping)\n",
    "\n",
    "    ## for each row, trying to find the first time it reaches\n",
    "    ## non-positive health outcome\n",
    "    res = np.argmax(res <= 0, axis=1)\n",
    "\n",
    "    ## calculating the negative of average length of period till\n",
    "    ## reaching a nonpositive health outcome\n",
    "    rtn_val = -res.mean()\n",
    "\n",
    "    return rtn_val\n",
    "\n",
    "def q3_gpu(n_runs=1000, n_steps=4160, mu=3.0, sigma=1,\n",
    "           rho_ub=0.95, rho_lb=-0.95, rho_n=200, rand_seed=25):\n",
    "    '''\n",
    "    \"Embarrassing\" application of finding the argmin rho for minimizing\n",
    "    the number of negative-or-zero health occurrences (with AR(1) process)\n",
    "\n",
    "    Input:\n",
    "    - n_runs: number of lives to simulate\n",
    "    - n_steps: number of periods to simulate\n",
    "    - mu: parameter value; also used as starting point\n",
    "    - sigma: standard dev. of the error term (~N(0, sigma))\n",
    "    - rho_ub: upper bound for the rho; rho is the parameter of AR(1)\n",
    "    - rho_lb: lower bound for the rho\n",
    "    - rho_n: number of rho cases to be used for simulation\n",
    "    - rand_seed: random seed for replication reasons (for the errors)\n",
    "\n",
    "    Output:\n",
    "    - elapsed (printed): time taken for overall computation\n",
    "    - best_rate, best_rho (printed): best (i.e., lowest) rate of non-\n",
    "        positive cases, and the accompanying rho\n",
    "    - q3_gpu_results.csv (csv output): collects rho and rate\n",
    "\n",
    "    '''\n",
    "    # Set up OpenCL context and command queue\n",
    "    ctx = cl.create_some_context()\n",
    "    queue = cl.CommandQueue(ctx)\n",
    "\n",
    "    # timing starts\n",
    "    t0 = time.time()\n",
    "\n",
    "    # generating a vector of epsilons (errors); length n_runs*n_steps\n",
    "    NT = int(n_runs*n_steps)\n",
    "    rand_gen = clrand.PhiloxGenerator(ctx, seed=rand_seed)\n",
    "    eps = rand_gen.normal(queue, NT, np.float32,\n",
    "                          mu=0, sigma=sigma)\n",
    "    \n",
    "    # establishing boundaries for each simulated walk\n",
    "    # necessary for performing scans only within lives and not between\n",
    "    seg_boundaries = [1] + [0]*(n_steps-1)\n",
    "    seg_boundaries = np.array(seg_boundaries, dtype=np.uint8)\n",
    "    seg_boundary_flags = np.tile(seg_boundaries, int(n_runs))\n",
    "    seg_boundary_flags = cl_array.to_device(queue, seg_boundary_flags)\n",
    "\n",
    "    # Defining segmented kernel operation\n",
    "    prefix_sum = GenericScanKernel(ctx, np.float32,\n",
    "                 arguments=\"__global float *ary, __global char *segflags, \"\n",
    "                           \"__global float rho, __global float *out\",\n",
    "                 input_expr=\"ary[i]\",\n",
    "                 scan_expr=\"across_seg_boundary ? b : (rho*a+b)\", neutral=\"0\",\n",
    "                 is_segment_start_expr=\"segflags[i]\",\n",
    "                 output_statement=\"out[i] = item\",\n",
    "                 options=[])\n",
    "\n",
    "    # Allocate space for result of kernel on device\n",
    "    dev_result = cl_array.empty_like(eps)\n",
    "\n",
    "    # All cases of rho\n",
    "    rho_cases = np.linspace(rho_lb, rho_ub, num=rho_n, dtype=np.float32)\n",
    "\n",
    "    # shape that the \"matrix\" version should take\n",
    "    shaping = (int(n_runs), int(n_steps))\n",
    "\n",
    "    # Embarrassing implementation of grid search\n",
    "    best_length = -np.inf # sentinel for grid search\n",
    "    best_rho = None\n",
    "    rho_length_lst = []\n",
    "    for rho in rho_cases:\n",
    "        rho_ = np.float32(rho) # just in case type mismatch occurs\n",
    "        # calculating the average length\n",
    "        candidate = -crit_fn(rho_, mu, shaping, eps,\n",
    "                             seg_boundary_flags, prefix_sum)\n",
    "        # recording the rho and average length\n",
    "        rho_length_lst.append([rho_, candidate])\n",
    "\n",
    "        # updating the best case\n",
    "        if candidate > best_length:\n",
    "            best_length = candidate\n",
    "            best_rho = rho_\n",
    "\n",
    "    # printing the best cases\n",
    "    print(\"Best avg. length of periods is %10.6f\" % best_length)\n",
    "    print(\"This is achieved by rho of %6.5f\" % best_rho)    \n",
    "\n",
    "    # exporting rho_length_lst\n",
    "    df = pd.DataFrame(rho_length_lst, columns=['rho', 'avg_length'])\n",
    "    df.to_csv(\"q3_gpu_results.csv\", index=False)\n",
    "\n",
    "    # elapsed time\n",
    "    final_time = time.time()\n",
    "    elapsed = final_time - t0\n",
    "    print(\"Simulation required %10.6f seconds\" % elapsed)\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    q3_gpu()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D-(2) q3_gpu.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=q3_gpu      # job name\n",
    "#SBATCH --output=q3_gpu.out # output log file\n",
    "#SBATCH --error=q3_gpu.err  # error file\n",
    "#SBATCH --time=00:20:00  # 5 minutes of wall time\n",
    "#SBATCH --nodes=1        # 1 GPU node\n",
    "#SBATCH --partition=gpu2 # GPU2 partition\n",
    "#SBATCH --ntasks=1       # 1 CPU core to drive GPU\n",
    "#SBATCH --gres=gpu:1     # Request 1 GPU\n",
    "\n",
    "module load cuda\n",
    "module load mpi4py/3.0.1a0_py3\n",
    "\n",
    "python ./q3_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E. Question 4-(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E-(1) q4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import scipy.optimize as opt\n",
    "import time\n",
    "\n",
    "def crit_fn_mpi(par, *args):\n",
    "    '''\n",
    "    Criterion function to be used in mpi4py implementation\n",
    "    of finding optimal rho (and average length of periods)\n",
    "    using scipy.optimize.minimize_scalar.\n",
    "\n",
    "    Inputs:\n",
    "    - par: the rho value to be tested (and optimized later)\n",
    "    - *args: broken down into...\n",
    "        - mu: mu value used in the AR(1) process\n",
    "        - eps: numpy array (shape (n_runs, n_steps)) of AR(1) errors\n",
    "    \n",
    "    Outputs:\n",
    "    - rtn_val: negative of the average length of periods until\n",
    "        reaching nonpositive health outcomes; negative one is multiplied\n",
    "        as we are using a minimization function (to find the maximum\n",
    "        average length)\n",
    "\n",
    "    '''\n",
    "    ## unravelling the arguments\n",
    "    mu, eps = args\n",
    "    rho = np.float32(par)\n",
    "\n",
    "    ## result of the below process stored here\n",
    "    result = np.empty_like(eps, dtype=np.float32)\n",
    "    n_steps = int(result.shape[1])\n",
    "\n",
    "    ## implementing the scan-like procedure for weighted sum\n",
    "    ## of epsilons to be used for the AR(1) process\n",
    "    for i in range(n_steps):\n",
    "        if i == 0:\n",
    "            input_col = eps[:, i]\n",
    "        else:\n",
    "            input_col = result[:, i-1] * rho + eps[:, i]\n",
    "        result[:, i] = input_col\n",
    "\n",
    "    ## adding mu to finish things\n",
    "    result = result + mu\n",
    "    # print(result)\n",
    "\n",
    "    ## for each row, trying to find the first time it reaches\n",
    "    ## non-positive health outcome\n",
    "    res = np.argmax(result <= 0, axis=1)\n",
    "\n",
    "    ## calculating the negative of average length of period till\n",
    "    ## reaching a nonpositive health outcome\n",
    "    rtn_val = -res.mean()\n",
    "\n",
    "    return rtn_val\n",
    "\n",
    "def q4_a(n_runs=1000, n_steps=4160, mu=3.0, sigma=1.0,\n",
    "         rho_ub=0.95, rho_lb=-0.95, rand_seed=25):\n",
    "    '''\n",
    "    Execution function for MPI4PY + optimize.minimize_scalar\n",
    "    implementation of finding the best rho\n",
    "\n",
    "    Inputs:\n",
    "    - n_runs: number of lives to simulate\n",
    "    - n_steps: number of periods to simulate\n",
    "    - mu: parameter for the AR(1) process; also starting health level\n",
    "    - sigma: scale for the epsilons ~ N(0, sigma)\n",
    "    - rho_ub: upper bound for rho (parameter for the AR(1) process)\n",
    "    - rho_lb: lower bound for rho\n",
    "    - rand_seed: randomization seed for replicability\n",
    "\n",
    "    Outputs: None\n",
    "    - All relevant outputs are made in the function\n",
    "       \"q4_mpi_part\"; see below for documentation\n",
    "\n",
    "    '''\n",
    "    # timing starts\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # randomizing\n",
    "    np.random.seed(rand_seed)\n",
    "    total_eps = sts.norm.rvs(loc=0, scale=sigma, size=(n_runs, n_steps))\n",
    "\n",
    "    q4_mpi_part(mu, total_eps, rho_ub, rho_lb, t0)\n",
    "\n",
    "    return None\n",
    "\n",
    "def q4_mpi_part(mu, total_eps, rho_ub, rho_lb, t0):\n",
    "    '''\n",
    "    MPI4PY and optimize.minimize_scalar implementation\n",
    "    for finding the best rho\n",
    "\n",
    "    Inputs:\n",
    "    - mu: parameter for the AR(1) process; also starting health level\n",
    "    - total_eps: matrix of normal errors ~ N(0, sigma), size=(n_runs, n_steps)\n",
    "    - rho_ub: upper bound for rho (parameter for the AR(1) process)\n",
    "    - rho_lb: lower bound for rho\n",
    "\n",
    "    Outputs: \n",
    "    - q4_mpi_result.csv (saved in directory): output containing rank,\n",
    "       best rho and best average length of first nonpositive health outcome\n",
    "    - elapsed (printed) \n",
    "\n",
    "    '''\n",
    "    # Setting up the communicator\n",
    "    comm = MPI.COMM_WORLD  \n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    \n",
    "    # setting up how many rows to run in the process\n",
    "    n_runs = total_eps.shape[0]\n",
    "    rows_per_rank = int(n_runs/size)\n",
    "    \n",
    "    # subsetting the epsilons\n",
    "    sub_eps = total_eps[(rows_per_rank*rank):(rows_per_rank*(rank+1)), :]\n",
    "     \n",
    "    # optimizing in the subcase\n",
    "    sub_result = opt.minimize_scalar(crit_fn_mpi,\n",
    "        args=((mu, sub_eps)), bounds=(rho_lb, rho_ub))\n",
    "    \n",
    "    # setting up the vector to return\n",
    "    sub_vector = np.array([rank, sub_result.x, -sub_result.fun],\n",
    "        dtype=\"float\")\n",
    "\n",
    "    # setting up an empty container for collecting results\n",
    "    result = None\n",
    "    if rank == 0:\n",
    "        result = np.empty(int(3*size), dtype=\"float\")\n",
    "\n",
    "    # collecting the results\n",
    "    comm.Gatherv(sendbuf=sub_vector, recvbuf=result, root=0)\n",
    "\n",
    "    # printing the results and summarizing\n",
    "    if rank == 0:\n",
    "        res = result.reshape((size, 3))\n",
    "        res_df = pd.DataFrame(res, columns=['rank', 'rho', 'avg_length'])\n",
    "        res_df.to_csv(\"q4_mpi_result.csv\", index=False)\n",
    "\n",
    "        elapsed = time.time() - t0\n",
    "        print(\"Computation time is {} seconds\".format(elapsed))\n",
    "\n",
    "    return None    \n",
    "\n",
    "def main():\n",
    "    q4_a()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E-(2) q4_try.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name=q4_actual\n",
    "#SBATCH --error=q4_try.err\n",
    "#SBATCH --output=q4_try.out\n",
    "#SBATCH --partition=broadwl\n",
    "#SBATCH --ntasks=20\n",
    "#SBATCH --constraint=fdr\n",
    "#SBATCH --mem-per-cpu=2G\n",
    "\n",
    "module load mpi4py/3.0.1a0_py3\n",
    "\n",
    "mpirun -n 20 python ./q4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part F. Question 4-(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-(1) q4_gpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "import pyopencl.array as cl_array\n",
    "import pyopencl.clrandom as clrand\n",
    "import pyopencl.tools as cltools\n",
    "import scipy.stats as sts\n",
    "import time\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "\n",
    "from pyopencl.scan import GenericScanKernel\n",
    "\n",
    "def crit_fn(par, *args):\n",
    "    '''\n",
    "    Criterion function to be used in PyOpenCL implementation\n",
    "    of finding optimal rho (and average length of periods)\n",
    "    using scipy.optimize.minimize_scalar.\n",
    "\n",
    "    Inputs:\n",
    "    - par: the rho value to be tested (and optimized later)\n",
    "    - *args: broken down into...\n",
    "        - mu: mu value used in the AR(1) process\n",
    "        - shaping: length-2 tuple; =(n_runs, n_steps)\n",
    "        - eps: PyOpenCL array (length n_runs*n_steps) of AR(1) errors\n",
    "        - boundaries: PyOpenCL array of segmented boundaries, to be\n",
    "            used in the scan kernel\n",
    "    \n",
    "    Outputs:\n",
    "    - rtn_val: negative of the average length of periods until\n",
    "        reaching nonpositive health outcomes; negative one is multiplied\n",
    "        as we are using a minimization function (to find the maximum\n",
    "        average length)\n",
    "\n",
    "    '''\n",
    "    ## unravelling the arguments\n",
    "    mu, shaping, eps, boundaries, prefix_sum = args\n",
    "    rho = par\n",
    "\n",
    "    ## generating an array of results, then calculating the AR(1) process\n",
    "    results = cl_array.empty_like(eps)\n",
    "    prefix_sum(eps, boundaries, rho, results)\n",
    "    results = results + mu\n",
    "\n",
    "    ## reshaping; row = number of lives, column = number of periods\n",
    "    res = results.get().reshape(shaping)\n",
    "\n",
    "    ## for each row, trying to find the first time it reaches\n",
    "    ## non-positive health outcome\n",
    "    res = np.argmax(res <= 0, axis=1)\n",
    "\n",
    "    ## calculating the negative of average length of period till\n",
    "    ## reaching a nonpositive health outcome\n",
    "    rtn_val = -res.mean()\n",
    "\n",
    "    return rtn_val\n",
    "\n",
    "def q4_gpu(n_runs=1000, n_steps=4160, mu=3.0, sigma=1,\n",
    "           rho_ub=0.95, rho_lb=-0.95, rand_seed=25):\n",
    "    '''\n",
    "    PyOpenCL implementation of finding optimal rho\n",
    "    (and average length of periods) using\n",
    "    scipy.optimize.minimize_scalar.\n",
    "\n",
    "    Input:\n",
    "    - n_runs: number of lives to simulate\n",
    "    - n_steps: number of periods to simulate\n",
    "    - mu: parameter value; also used as starting point\n",
    "    - sigma: standard dev. of the error term (~N(0, sigma))\n",
    "    - rho_ub: upper bound for the rho; rho is the parameter of AR(1)\n",
    "    - rho_lb: lower bound for the rho\n",
    "    - rand_seed: random seed for replication reasons (for the errors)\n",
    "\n",
    "    Output:\n",
    "    - elapsed (printed): time taken for overall computation\n",
    "    - best_rate, best_rho (printed): best (i.e., lowest) avg length\n",
    "        of first nonpositive occurrences, and the accompanying rho\n",
    "\n",
    "    '''\n",
    "    # Set up OpenCL context and command queue\n",
    "    ctx = cl.create_some_context()\n",
    "    queue = cl.CommandQueue(ctx)\n",
    "\n",
    "    # timing starts\n",
    "    t0 = time.time()\n",
    "\n",
    "    # generating a vector of epsilons (errors); length n_runs*n_steps\n",
    "    NT = int(n_runs*n_steps)\n",
    "    rand_gen = clrand.PhiloxGenerator(ctx, seed=rand_seed)\n",
    "    eps = rand_gen.normal(queue, NT, np.float32,\n",
    "                          mu=0, sigma=sigma)\n",
    "\n",
    "    # establishing boundaries for each simulated walk\n",
    "    # necessary for performing scans only within lives and not between\n",
    "    seg_boundaries = [1] + [0]*(n_steps-1)\n",
    "    seg_boundaries = np.array(seg_boundaries, dtype=np.uint8)\n",
    "    seg_boundary_flags = np.tile(seg_boundaries, int(n_runs))\n",
    "    seg_boundary_flags = cl_array.to_device(queue, seg_boundary_flags)\n",
    "\n",
    "    # Defining segmented kernel operation\n",
    "    prefix_sum = GenericScanKernel(ctx, np.float32,\n",
    "                 arguments=\"__global float *ary, __global char *segflags, \"\n",
    "                           \"__global float rho, __global float *out\",\n",
    "                 input_expr=\"ary[i]\",\n",
    "                 scan_expr=\"across_seg_boundary ? b : (rho*a+b)\", neutral=\"0\",\n",
    "                 is_segment_start_expr=\"segflags[i]\",\n",
    "                 output_statement=\"out[i] = item\",\n",
    "                 options=[])\n",
    "\n",
    "    # using scipy.optimize.minimize_scalar\n",
    "    shaping = (int(n_runs), int(n_steps))\n",
    "    bounded = (np.float32(rho_lb), np.float32(rho_ub))\n",
    "    result = opt.minimize_scalar(\n",
    "        crit_fn, args=((mu, shaping, eps, seg_boundary_flags, prefix_sum)),\n",
    "        bounds=bounded)\n",
    "\n",
    "    # best_rho and best_length\n",
    "    best_rho, best_length = result.x, -result.fun\n",
    "    print(\"Best avg. length of periods is %10.6f\" % best_length)\n",
    "    print(\"This is achieved by rho of %6.5f\" % best_rho)\n",
    "\n",
    "    # elapsed time\n",
    "    final_time = time.time()\n",
    "    elapsed = final_time - t0\n",
    "    print(\"Simulation required %10.6f seconds\" % elapsed)\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    q4_gpu()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-(2) q4_gpu.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=q4_gpu      # job name\n",
    "#SBATCH --output=q4_gpu.out # output log file\n",
    "#SBATCH --error=q4_gpu.err  # error file\n",
    "#SBATCH --time=00:20:00  # 5 minutes of wall time\n",
    "#SBATCH --nodes=1        # 1 GPU node\n",
    "#SBATCH --partition=gpu2 # GPU2 partition\n",
    "#SBATCH --ntasks=1       # 1 CPU core to drive GPU\n",
    "#SBATCH --gres=gpu:1     # Request 1 GPU\n",
    "\n",
    "module load cuda\n",
    "module load mpi4py/3.0.1a0_py3\n",
    "\n",
    "python ./q4_gpu.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
